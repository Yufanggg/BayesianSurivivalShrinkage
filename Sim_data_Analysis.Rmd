---
title: "Generate_sim_data"
author: "Yufang Wang"
date: "2025-03-18"
output: pdf_document
---

# Step 1: Set up the environment
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
setwd("G:/MasterThesis/Code/")   # "C:/Users/Alisa_Wang/Desktop/MasterThesis/Code/")
source("./Functions.R")

install_and_load <- function(packages) {
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      install.packages(pkg, dependencies = TRUE)
    }
    library(pkg, character.only = TRUE) }
  
}

# List of required packages
required_packages <- c("rstan", "rstantools", "coda", "readr", "survival", "splines2", "dplyr", "simsurv", "Hmisc", "caret")
# Install and/or load packages
install_and_load(required_packages)
```


# Step 2: Generate simulated data
```{r, echo=TRUE}
set.seed(123)
n_samples <- 500
n_features <- 10 

design_matrix <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features) 

# Randomly select half of the columns and convert them to binary data
select_columns <- sample(1:n_features, n_features/2)
design_matrix[, select_columns] <- ifelse(design_matrix[, select_columns] > 0, 1, -1)


# View the first few rows of the dataset
head(design_matrix)
     
     
covariates <- data.frame(design_matrix)
colnames(covariates) <- paste0("Feature", 1:ncol(covariates))
covariates$id <- 1:n_samples
# Define the effects of the covariates
beta <- rnorm(n_features)
names(beta) <- paste0("Feature", 1:n_features)


# Simulate the survival data
sim_data <- simsurv(
  dist = "weibull",
  lambdas = 2, # scale
  gammas = 5, # shape for weibull
  betas = beta,
  x = covariates,
  mixture = FALSE,
  maxt = 5  # Maximum follow-up time
)


sim_data <- sim_data |> left_join(covariates, by = "id") |> 
  mutate(
    censtime = runif(n_samples, 0.5, 2),
    status = as.numeric(eventtime <= censtime),
    obstime = pmin(eventtime, censtime)
    ) |> select("obstime", "status", colnames(covariates))

head(sim_data)

rm(design_matrix, covariates, n_features, n_samples, required_packages, select_columns, install_and_load)
print(beta)


# Get a list of all objects in the environment
all_objects <- mget(ls())

# Save all objects to an .Rds file
saveRDS(all_objects, file = "Simulated_Data.Rds")
```

# Step 3: Model performance metric
```{r, echo=TRUE}
cross_validation <- function(whole_dataset, baseline_modelling = "bSplines", num_folds = 5){
  # create the cross-validation folds
  folds <- createFolds(whole_dataset$status, k = num_folds, list = TRUE, returnTrain = FALSE)
  cross_val_metric <- list()
  rMSE_s = matrix(nrow = 5, ncol = 55); Brier_scores =  rep(NA, 5); C_indices =  rep(NA, 5); FDR_vals =  rep(NA, 5)
  for (i in 1:num_folds){
    fold_indices <- folds[[i]]
    training_data = whole_dataset[-fold_indices, ]
    testing_data = whole_dataset[fold_indices, ]
    stan_data <- stan_data_Constructer(training_dataset = training_data, testing_dataset = testing_data, obs_window = 5)
    model_fit <- Bayesian_Survival_model(stan_data = stan_data, baseline_assumption = baseline_modelling)
    
    #extract the info from the bayesian model fit
    model_result <- Bayesian_Survival_result_Extract(bayesian_model_fit = model_fit)
    
    ComparsionValues <- list(
      Beta_reference = c(beta, rep(0, 45)),
      test_t = testing_data$obstime,
      test_status = testing_data$status,
      Selection_reference = c(rep(TRUE, 10), rep(FALSE, 45))
      )
    model_metric <- Model_performance_eval(model_result = model_result, ComparsionValues)
    rMSE_s[i, ] <- model_metric$rMSE
    Brier_scores[i] <- model_metric$Brier_score
    C_indices[i] <- model_metric$C_index
    FDR_vals[i] <- model_metric$FDR
  }
  cross_val_metric$rMSE_s <- rMSE_s
  cross_val_metric$Brier_scores <- Brier_scores
  cross_val_metric$C_indices <- C_indices
  cross_val_metric$C_indices <- FDR_vals
  
  return(cross_val_metric)
}

cross_val_metric <- cross_validation(whole_dataset = sim_data)

metric_visualization(cross_val_metric)
```

# Step 3: visualize the model metric results

```{r, echo=TRUE}
rMSE_s <- cross_val_metric$rMSE_s
Brier_scores <- cross_val_metric$Brier_scores
C_indices <- cross_val_metric$C_indices
FDR_vals <- cross_val_metric$FDR_vals

# Adjust the margins
par(mfrow = c(2, 2))
#-----------------------------
# visual the result of rMSE_s
#-----------------------------
mean_values <- colMeans(rMSE_s)
sd_values <- apply(rMSE_s, 2, sd)
# Plot the mean values
plot(
  mean_values,
  type = "o",
  col = "blue",
  xlab = "estimated Betas",
  ylab = "estimated Value of Betas",
  ylim = c(0, 2),
  main = "Mean Values with Error Bars",
  pch = 16
)
# Add error bars
arrows(
  1:55,
  mean_values - sd_values,
  1:55,
  mean_values + sd_values,
  angle = 90,
  code = 3,
  length = 0.05,
  col = "red"
)

# Add a legend
legend(
  "topright",
  legend = c("Mean Values", "Error Bars"),
  col = c("blue", "red"),
  pch = 16,
  lty = 1
)

#-----------------------------
# visual the result of Brier_scores
#-----------------------------
boxplot(Brier_scores,
        main = "Brier_scores for the model prediction",
        ylab = "Brier_scores",
        col = "blue")


#-----------------------------
# visual the result of C_indices
#-----------------------------
boxplot(C_indices,
        main = "C_indices for the model prediction",
        ylab = "C_indices",
        col = "green")

#-----------------------------
# visual the result of FDR_vals
#-----------------------------
boxplot(FDR_vals,
        main = "FDR for the model prediction",
        ylab = "FDR",
        col = "orange")
```


```{r, echo=TRUE}
source("./bSpline_stan_constructor.R")
stan_data <- stan_bSpline_data_Constructer(training_dataset = sim_data, testing_dataset = sim_data, obs_window = 5)
model_fit <- Bayesian_Survival_model(stan_data = stan_data, baseline_assumption = "bSplines") # #exponential, weibull,  bSplines
#Bayesian_Survival_model_check(model_fit) # model diagnostic

#extract the info from the bayesian model fit
model_result <- Bayesian_Survival_result_Extract(bayesian_model_fit = model_fit)

ComparsionValues <- list(
  Beta_reference = c(beta, rep(0, 45)),
  test_t = sim_data$obstime,
  test_status = sim_data$status,
  Selection_reference =c(rep(TRUE, 10), rep(FALSE, 45))
)

Model_performance_eval(model_result, ComparsionValues)
```

# Implemented it in the bayesian code
```{r, echo=TRUE}
cross_validation(dataset = sim_data,
                 method = "exponential",
                 spilit = FALSE) {
  X <-
    model.matrix( ~ . ^ 2, data = dataset[,!(names(dataset) %in% c("id", "obstime", "status"))])
  dim(X)
  
  column_names = colnames(X)
  main_names =  column_names[!grepl(":", column_names) &
                               column_names != "(Intercept)"]
  X_main = X[, main_names]
  
  int_names =  column_names[grepl(":", column_names)]
  X_int = X[, int_names]
  
  p <- dim(X_main)[2]
  q <- dim(X_int)[2]
  
  main_indices_for_int = find_main_effect_indices(int_names, main_names)
  g1 <- g(main_indices_for_int, 1)
  g2 <- g(main_indices_for_int, 2)
  
  
  # Prepares data and parameter input for Stan.
  stan_data <- list(
    # response and time variable
    nevent = nrow(dataset[dataset$status == 1, ]),
    nrcens = nrow(dataset[dataset$status == 0, ]),
    t_event = dataset[dataset$status == 1, "obstime"],
    t_rcens = dataset[dataset$status == 0, "obstime"],
    
    # predictor matrices (time-fixed)
    p = p,
    q = q,
    x_event = X_main[dataset$status == 1,],
    x_int_event =  X_int[dataset$status == 1,],
    
    x_rcens = X_main[dataset$status == 0,],
    x_int_rcens = X_int[dataset$status == 0,],
    
    # link the interaction effect with the corresponding main effects
    g1 = g1,
    g2 = g2,
    
    # for prediction
    nnew = nrow(dataset),
    x_new = X_main,
    x_int_new = X_int,
    t_new = dataset[, "obstime"]
  )
  
  rm(dataset,
     X,
     X_int,
     X_main,
     p,
     q,
     g1,
     g2,
     int_names,
     main_names,
     column_names)
  
  # fit the model
  model <-
    Bayesian_Survival_includingbaseline(stan_data = stan_data, baseline_assumption = "bSplines") # #exponential, weibull,  bSplines
  return (model)
}
```