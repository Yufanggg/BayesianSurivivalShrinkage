---
title: "Generate_sim_data"
author: "Yufang Wang"
date: "2025-03-18"
output: pdf_document
---

# Step 1: Set up the environment
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
setwd("G:/MasterThesis/Code/")   # "C:/Users/Alisa_Wang/Desktop/MasterThesis/Code/")
source("./function_file/Functions.R")

install_and_load <- function(packages) {
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      install.packages(pkg, dependencies = TRUE)
    }
    library(pkg, character.only = TRUE) }
  
}

# List of required packages
required_packages <- c("rstan", "rstantools", "coda", "readr", "survival", "splines2", "dplyr", "simsurv", "Hmisc", "caret")
# Install and/or load packages
install_and_load(required_packages)
```


# Step 2: Generate simulated data
```{r, echo=TRUE}
set.seed(123)
n_samples <- 500
n_features <- 10 

design_matrix <- matrix(rnorm(n_samples * n_features), nrow = n_samples, ncol = n_features) 

# Randomly select half of the columns and convert them to binary data
select_columns <- sample(1:n_features, n_features/2)
design_matrix[, select_columns] <- ifelse(design_matrix[, select_columns] > 0, 1, -1)


# View the first few rows of the dataset
head(design_matrix)
     
     
covariates <- data.frame(design_matrix)
colnames(covariates) <- paste0("Feature", 1:ncol(covariates))
covariates$id <- 1:n_samples
# Define the effects of the covariates
beta <- rnorm(n_features)
names(beta) <- paste0("Feature", 1:n_features)


# Simulate the survival data
sim_data <- simsurv(
  dist = "weibull",
  lambdas = 2, # scale
  gammas = 5, # shape for weibull
  betas = beta,
  x = covariates,
  mixture = FALSE,
  maxt = 5  # Maximum follow-up time
)


sim_data <- sim_data |> left_join(covariates, by = "id") |> 
  mutate(
    censtime = runif(n_samples, 0.5, 2),
    status = as.numeric(eventtime <= censtime),
    obstime = pmin(eventtime, censtime)
    ) |> select("obstime", "status", colnames(covariates))

head(sim_data)

rm(design_matrix, covariates, n_features, n_samples, required_packages, select_columns, install_and_load)
print(beta)


# Get a list of all objects in the environment
all_objects <- mget(ls())

# Save all objects to an .Rds file
saveRDS(all_objects, file = "./Data/Simulated_Data.Rds")
```

# Step 3: Model performance metric
```{r, echo=TRUE}
cross_validation <- function(whole_dataset, baseline_modelling = "bSplines", num_folds = 5){
  # create the cross-validation folds
  folds <- createFolds(whole_dataset$status, k = num_folds, list = TRUE, returnTrain = FALSE)
  cross_val_metric <- list()
  rMSE_s = matrix(nrow = 5, ncol = 55); Brier_scores =  rep(NA, 5); C_indices =  rep(NA, 5); FDR_vals =  rep(NA, 5)
  for (i in 1:num_folds){
    fold_indices <- folds[[i]]
    training_data = whole_dataset[-fold_indices, ]
    testing_data = whole_dataset[fold_indices, ]
    stan_data <- stan_data_Constructer(training_dataset = training_data, testing_dataset = testing_data, obs_window = 5)
    model_fit <- Bayesian_Survival_model(stan_data = stan_data, baseline_assumption = baseline_modelling)
    
    #extract the info from the bayesian model fit
    model_result <- Bayesian_Survival_result_Extract(bayesian_model_fit = model_fit)
    
    ComparsionValues <- list(
      Beta_reference = c(beta, rep(0, 45)),
      test_t = testing_data$obstime,
      test_status = testing_data$status,
      Selection_reference = c(rep(TRUE, 10), rep(FALSE, 45))
      )
    model_metric <- Model_performance_eval(model_result = model_result, ComparsionValues)
    rMSE_s[i, ] <- model_metric$rMSE
    Brier_scores[i] <- model_metric$Brier_score
    C_indices[i] <- model_metric$C_index
    FDR_vals[i] <- model_metric$FDR
  }
  cross_val_metric$rMSE_s <- rMSE_s
  cross_val_metric$Brier_scores <- Brier_scores
  cross_val_metric$C_indices <- C_indices
  cross_val_metric$FDR_vals <- FDR_vals
  
  return(cross_val_metric)
}

cross_val_metric <- cross_validation(whole_dataset = sim_data)

# Step 3: visualize the model metric results
metric_visualization(cross_val_metric)
```

